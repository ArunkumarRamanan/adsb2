I0216 17:25:39.025787 29927 caffe.cpp:183] Using GPUs 0
I0216 17:25:39.626803 29927 solver.cpp:54] Initializing solver from parameters: 
train_net: "train.prototxt"
test_net: "val.prototxt"
test_iter: 0
test_interval: 1000000
base_lr: 0.01
display: 2000
max_iter: 1000000
lr_policy: "multistep"
gamma: 0.1
momentum: 0.9
weight_decay: 0.0005
snapshot: 2000
snapshot_prefix: "./snapshots/fcn"
solver_mode: GPU
device_id: 0
random_seed: 5
test_initialization: true
average_loss: 200
stepvalue: 10000
I0216 17:25:39.626852 29927 solver.cpp:86] Creating training net from train_net file: train.prototxt
I0216 17:25:39.627358 29927 net.cpp:50] Initializing net from parameters: 
name: "FCN"
force_backward: true
state {
  phase: TRAIN
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  transform_param {
    mirror: false
    crop_size: 0
    mean_value: 0
  }
  data_param {
    source: "db/train/images"
    batch_size: 1
    backend: LMDB
  }
}
layer {
  name: "label"
  type: "Data"
  top: "label"
  data_param {
    source: "db/train/labels"
    batch_size: 1
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 100
    pad: 50
    kernel_size: 5
    group: 1
    stride: 2
    weight_filler {
      type: "gaussian"
      mean: 0
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 200
    pad: 0
    kernel_size: 5
    group: 1
    stride: 2
    weight_filler {
      type: "gaussian"
      mean: 0
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 300
    pad: 0
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "gaussian"
      mean: 0
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 300
    pad: 0
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "gaussian"
      mean: 0
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "drop"
  type: "Dropout"
  bottom: "conv4"
  top: "conv4"
  dropout_param {
    dropout_ratio: 0.1
  }
}
layer {
  name: "score_classes"
  type: "Convolution"
  bottom: "conv4"
  top: "score_classes"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 2
    pad: 0
    kernel_size: 1
    group: 1
    stride: 1
    weight_filler {
      type: "gaussian"
      mean: 0
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "upscore"
  type: "Deconvolution"
  bottom: "score_classes"
  top: "upscore"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 2
    bias_term: true
    pad: 8
    kernel_size: 31
    stride: 16
    weight_filler {
      type: "bilinear"
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "score"
  type: "Crop"
  bottom: "upscore"
  bottom: "data"
  top: "score"
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "score"
  bottom: "label"
  top: "loss"
  loss_param {
    normalize: true
  }
}
I0216 17:25:39.627486 29927 layer_factory.hpp:76] Creating layer data
I0216 17:25:39.627601 29927 net.cpp:111] Creating Layer data
I0216 17:25:39.627614 29927 net.cpp:434] data -> data
I0216 17:25:39.628212 29934 db_lmdb.cpp:22] Opened lmdb db/train/images
I0216 17:25:39.628294 29927 data_layer.cpp:44] output data size: 1,1,178,237
I0216 17:25:39.633180 29927 net.cpp:156] Setting up data
I0216 17:25:39.633203 29927 net.cpp:164] Top shape: 1 1 178 237 (42186)
I0216 17:25:39.633214 29927 layer_factory.hpp:76] Creating layer data_data_0_split
I0216 17:25:39.633256 29927 net.cpp:111] Creating Layer data_data_0_split
I0216 17:25:39.633268 29927 net.cpp:478] data_data_0_split <- data
I0216 17:25:39.633282 29927 net.cpp:434] data_data_0_split -> data_data_0_split_0
I0216 17:25:39.633297 29927 net.cpp:434] data_data_0_split -> data_data_0_split_1
I0216 17:25:39.633316 29927 net.cpp:156] Setting up data_data_0_split
I0216 17:25:39.633327 29927 net.cpp:164] Top shape: 1 1 178 237 (42186)
I0216 17:25:39.633334 29927 net.cpp:164] Top shape: 1 1 178 237 (42186)
I0216 17:25:39.633342 29927 layer_factory.hpp:76] Creating layer label
I0216 17:25:39.633389 29927 net.cpp:111] Creating Layer label
I0216 17:25:39.633399 29927 net.cpp:434] label -> label
I0216 17:25:39.634680 29936 db_lmdb.cpp:22] Opened lmdb db/train/labels
I0216 17:25:39.634829 29927 data_layer.cpp:44] output data size: 1,1,178,237
I0216 17:25:39.635686 29927 net.cpp:156] Setting up label
I0216 17:25:39.635701 29927 net.cpp:164] Top shape: 1 1 178 237 (42186)
I0216 17:25:39.635709 29927 layer_factory.hpp:76] Creating layer conv1
I0216 17:25:39.635723 29927 net.cpp:111] Creating Layer conv1
I0216 17:25:39.635730 29927 net.cpp:478] conv1 <- data_data_0_split_0
I0216 17:25:39.635746 29927 net.cpp:434] conv1 -> conv1
I0216 17:25:39.736707 29927 net.cpp:156] Setting up conv1
I0216 17:25:39.736747 29927 net.cpp:164] Top shape: 1 100 137 167 (2287900)
I0216 17:25:39.736773 29927 layer_factory.hpp:76] Creating layer relu1
I0216 17:25:39.736788 29927 net.cpp:111] Creating Layer relu1
I0216 17:25:39.736796 29927 net.cpp:478] relu1 <- conv1
I0216 17:25:39.736805 29927 net.cpp:420] relu1 -> conv1 (in-place)
I0216 17:25:39.737013 29927 net.cpp:156] Setting up relu1
I0216 17:25:39.737025 29927 net.cpp:164] Top shape: 1 100 137 167 (2287900)
I0216 17:25:39.737032 29927 layer_factory.hpp:76] Creating layer pool1
I0216 17:25:39.737046 29927 net.cpp:111] Creating Layer pool1
I0216 17:25:39.737053 29927 net.cpp:478] pool1 <- conv1
I0216 17:25:39.737061 29927 net.cpp:434] pool1 -> pool1
I0216 17:25:39.737190 29927 net.cpp:156] Setting up pool1
I0216 17:25:39.737200 29927 net.cpp:164] Top shape: 1 100 69 84 (579600)
I0216 17:25:39.737207 29927 layer_factory.hpp:76] Creating layer conv2
I0216 17:25:39.737221 29927 net.cpp:111] Creating Layer conv2
I0216 17:25:39.737229 29927 net.cpp:478] conv2 <- pool1
I0216 17:25:39.737239 29927 net.cpp:434] conv2 -> conv2
I0216 17:25:39.743178 29927 net.cpp:156] Setting up conv2
I0216 17:25:39.743192 29927 net.cpp:164] Top shape: 1 200 33 40 (264000)
I0216 17:25:39.743207 29927 layer_factory.hpp:76] Creating layer relu2
I0216 17:25:39.743216 29927 net.cpp:111] Creating Layer relu2
I0216 17:25:39.743222 29927 net.cpp:478] relu2 <- conv2
I0216 17:25:39.743232 29927 net.cpp:420] relu2 -> conv2 (in-place)
I0216 17:25:39.743427 29927 net.cpp:156] Setting up relu2
I0216 17:25:39.743438 29927 net.cpp:164] Top shape: 1 200 33 40 (264000)
I0216 17:25:39.743445 29927 layer_factory.hpp:76] Creating layer pool2
I0216 17:25:39.743456 29927 net.cpp:111] Creating Layer pool2
I0216 17:25:39.743463 29927 net.cpp:478] pool2 <- conv2
I0216 17:25:39.743471 29927 net.cpp:434] pool2 -> pool2
I0216 17:25:39.743602 29927 net.cpp:156] Setting up pool2
I0216 17:25:39.743613 29927 net.cpp:164] Top shape: 1 200 17 20 (68000)
I0216 17:25:39.743620 29927 layer_factory.hpp:76] Creating layer conv3
I0216 17:25:39.743630 29927 net.cpp:111] Creating Layer conv3
I0216 17:25:39.743636 29927 net.cpp:478] conv3 <- pool2
I0216 17:25:39.743648 29927 net.cpp:434] conv3 -> conv3
I0216 17:25:39.750267 29927 net.cpp:156] Setting up conv3
I0216 17:25:39.750285 29927 net.cpp:164] Top shape: 1 300 15 18 (81000)
I0216 17:25:39.750300 29927 layer_factory.hpp:76] Creating layer relu3
I0216 17:25:39.750313 29927 net.cpp:111] Creating Layer relu3
I0216 17:25:39.750319 29927 net.cpp:478] relu3 <- conv3
I0216 17:25:39.750327 29927 net.cpp:420] relu3 -> conv3 (in-place)
I0216 17:25:39.750455 29927 net.cpp:156] Setting up relu3
I0216 17:25:39.750466 29927 net.cpp:164] Top shape: 1 300 15 18 (81000)
I0216 17:25:39.750473 29927 layer_factory.hpp:76] Creating layer conv4
I0216 17:25:39.750486 29927 net.cpp:111] Creating Layer conv4
I0216 17:25:39.750496 29927 net.cpp:478] conv4 <- conv3
I0216 17:25:39.750506 29927 net.cpp:434] conv4 -> conv4
I0216 17:25:39.759747 29927 net.cpp:156] Setting up conv4
I0216 17:25:39.759762 29927 net.cpp:164] Top shape: 1 300 13 16 (62400)
I0216 17:25:39.759773 29927 layer_factory.hpp:76] Creating layer relu4
I0216 17:25:39.759784 29927 net.cpp:111] Creating Layer relu4
I0216 17:25:39.759791 29927 net.cpp:478] relu4 <- conv4
I0216 17:25:39.759799 29927 net.cpp:420] relu4 -> conv4 (in-place)
I0216 17:25:39.760006 29927 net.cpp:156] Setting up relu4
I0216 17:25:39.760018 29927 net.cpp:164] Top shape: 1 300 13 16 (62400)
I0216 17:25:39.760025 29927 layer_factory.hpp:76] Creating layer drop
I0216 17:25:39.760036 29927 net.cpp:111] Creating Layer drop
I0216 17:25:39.760043 29927 net.cpp:478] drop <- conv4
I0216 17:25:39.760051 29927 net.cpp:420] drop -> conv4 (in-place)
I0216 17:25:39.760066 29927 net.cpp:156] Setting up drop
I0216 17:25:39.760076 29927 net.cpp:164] Top shape: 1 300 13 16 (62400)
I0216 17:25:39.760082 29927 layer_factory.hpp:76] Creating layer score_classes
I0216 17:25:39.760094 29927 net.cpp:111] Creating Layer score_classes
I0216 17:25:39.760100 29927 net.cpp:478] score_classes <- conv4
I0216 17:25:39.760112 29927 net.cpp:434] score_classes -> score_classes
I0216 17:25:39.760704 29927 net.cpp:156] Setting up score_classes
I0216 17:25:39.760715 29927 net.cpp:164] Top shape: 1 2 13 16 (416)
I0216 17:25:39.760730 29927 layer_factory.hpp:76] Creating layer upscore
I0216 17:25:39.760742 29927 net.cpp:111] Creating Layer upscore
I0216 17:25:39.760751 29927 net.cpp:478] upscore <- score_classes
I0216 17:25:39.760761 29927 net.cpp:434] upscore -> upscore
I0216 17:25:39.760957 29927 net.cpp:156] Setting up upscore
I0216 17:25:39.760967 29927 net.cpp:164] Top shape: 1 2 207 255 (105570)
I0216 17:25:39.760977 29927 layer_factory.hpp:76] Creating layer score
I0216 17:25:39.760998 29927 net.cpp:111] Creating Layer score
I0216 17:25:39.761005 29927 net.cpp:478] score <- upscore
I0216 17:25:39.761013 29927 net.cpp:478] score <- data_data_0_split_1
I0216 17:25:39.761021 29927 net.cpp:434] score -> score
I0216 17:25:39.761065 29927 net.cpp:156] Setting up score
I0216 17:25:39.761073 29927 net.cpp:164] Top shape: 1 2 178 237 (84372)
I0216 17:25:39.761080 29927 layer_factory.hpp:76] Creating layer loss
I0216 17:25:39.761092 29927 net.cpp:111] Creating Layer loss
I0216 17:25:39.761099 29927 net.cpp:478] loss <- score
I0216 17:25:39.761106 29927 net.cpp:478] loss <- label
I0216 17:25:39.761114 29927 net.cpp:434] loss -> loss
I0216 17:25:39.761134 29927 layer_factory.hpp:76] Creating layer loss
I0216 17:25:39.761353 29927 net.cpp:156] Setting up loss
I0216 17:25:39.761363 29927 net.cpp:164] Top shape: (1)
I0216 17:25:39.761369 29927 net.cpp:169]     with loss weight 1
I0216 17:25:39.761394 29927 net.cpp:237] loss needs backward computation.
I0216 17:25:39.761400 29927 net.cpp:237] score needs backward computation.
I0216 17:25:39.761406 29927 net.cpp:237] upscore needs backward computation.
I0216 17:25:39.761412 29927 net.cpp:237] score_classes needs backward computation.
I0216 17:25:39.761418 29927 net.cpp:237] drop needs backward computation.
I0216 17:25:39.761423 29927 net.cpp:237] relu4 needs backward computation.
I0216 17:25:39.761428 29927 net.cpp:237] conv4 needs backward computation.
I0216 17:25:39.761433 29927 net.cpp:237] relu3 needs backward computation.
I0216 17:25:39.761438 29927 net.cpp:237] conv3 needs backward computation.
I0216 17:25:39.761445 29927 net.cpp:237] pool2 needs backward computation.
I0216 17:25:39.761452 29927 net.cpp:237] relu2 needs backward computation.
I0216 17:25:39.761457 29927 net.cpp:237] conv2 needs backward computation.
I0216 17:25:39.761463 29927 net.cpp:237] pool1 needs backward computation.
I0216 17:25:39.761468 29927 net.cpp:237] relu1 needs backward computation.
I0216 17:25:39.761474 29927 net.cpp:237] conv1 needs backward computation.
I0216 17:25:39.761481 29927 net.cpp:241] label does not need backward computation.
I0216 17:25:39.761487 29927 net.cpp:241] data_data_0_split does not need backward computation.
I0216 17:25:39.761492 29927 net.cpp:241] data does not need backward computation.
I0216 17:25:39.761498 29927 net.cpp:284] This network produces output loss
I0216 17:25:39.761513 29927 net.cpp:298] Network initialization done.
I0216 17:25:39.761519 29927 net.cpp:299] Memory required for data: 25838812
I0216 17:25:39.761869 29927 solver.cpp:186] Creating test net (#0) specified by test_net file: val.prototxt
I0216 17:25:39.762034 29927 net.cpp:50] Initializing net from parameters: 
name: "FCN"
force_backward: true
state {
  phase: TEST
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  transform_param {
    mirror: false
    crop_size: 0
    mean_value: 0
  }
  data_param {
    source: "db/val/images"
    batch_size: 1
    backend: LMDB
  }
}
layer {
  name: "label"
  type: "Data"
  top: "label"
  data_param {
    source: "db/val/labels"
    batch_size: 1
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 100
    pad: 50
    kernel_size: 5
    group: 1
    stride: 2
    weight_filler {
      type: "gaussian"
      mean: 0
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 200
    pad: 0
    kernel_size: 5
    group: 1
    stride: 2
    weight_filler {
      type: "gaussian"
      mean: 0
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 300
    pad: 0
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "gaussian"
      mean: 0
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 300
    pad: 0
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "gaussian"
      mean: 0
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "drop"
  type: "Dropout"
  bottom: "conv4"
  top: "conv4"
  dropout_param {
    dropout_ratio: 0.1
  }
}
layer {
  name: "score_classes"
  type: "Convolution"
  bottom: "conv4"
  top: "score_classes"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 2
    pad: 0
    kernel_size: 1
    group: 1
    stride: 1
    weight_filler {
      type: "gaussian"
      mean: 0
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "upscore"
  type: "Deconvolution"
  bottom: "score_classes"
  top: "upscore"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 2
    bias_term: true
    pad: 8
    kernel_size: 31
    stride: 16
    weight_filler {
      type: "bilinear"
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "score"
  type: "Crop"
  bottom: "upscore"
  bottom: "data"
  top: "score"
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "score"
  bottom: "label"
  top: "loss"
  loss_param {
    normalize: true
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "score"
  bottom: "label"
  top: "accuracy"
}
I0216 17:25:39.762152 29927 layer_factory.hpp:76] Creating layer data
I0216 17:25:39.762342 29927 net.cpp:111] Creating Layer data
I0216 17:25:39.762352 29927 net.cpp:434] data -> data
I0216 17:25:39.762992 29938 db_lmdb.cpp:22] Opened lmdb db/val/images
I0216 17:25:39.763092 29927 data_layer.cpp:44] output data size: 1,1,286,286
I0216 17:25:39.763746 29927 net.cpp:156] Setting up data
I0216 17:25:39.763758 29927 net.cpp:164] Top shape: 1 1 286 286 (81796)
I0216 17:25:39.763767 29927 layer_factory.hpp:76] Creating layer data_data_0_split
I0216 17:25:39.763777 29927 net.cpp:111] Creating Layer data_data_0_split
I0216 17:25:39.763783 29927 net.cpp:478] data_data_0_split <- data
I0216 17:25:39.763794 29927 net.cpp:434] data_data_0_split -> data_data_0_split_0
I0216 17:25:39.763804 29927 net.cpp:434] data_data_0_split -> data_data_0_split_1
I0216 17:25:39.763816 29927 net.cpp:156] Setting up data_data_0_split
I0216 17:25:39.763828 29927 net.cpp:164] Top shape: 1 1 286 286 (81796)
I0216 17:25:39.763835 29927 net.cpp:164] Top shape: 1 1 286 286 (81796)
I0216 17:25:39.763841 29927 layer_factory.hpp:76] Creating layer label
I0216 17:25:39.763882 29927 net.cpp:111] Creating Layer label
I0216 17:25:39.763891 29927 net.cpp:434] label -> label
I0216 17:25:39.764870 29940 db_lmdb.cpp:22] Opened lmdb db/val/labels
I0216 17:25:39.765036 29927 data_layer.cpp:44] output data size: 1,1,286,286
I0216 17:25:39.765789 29927 net.cpp:156] Setting up label
I0216 17:25:39.765802 29927 net.cpp:164] Top shape: 1 1 286 286 (81796)
I0216 17:25:39.765810 29927 layer_factory.hpp:76] Creating layer label_label_0_split
I0216 17:25:39.765820 29927 net.cpp:111] Creating Layer label_label_0_split
I0216 17:25:39.765827 29927 net.cpp:478] label_label_0_split <- label
I0216 17:25:39.765836 29927 net.cpp:434] label_label_0_split -> label_label_0_split_0
I0216 17:25:39.765847 29927 net.cpp:434] label_label_0_split -> label_label_0_split_1
I0216 17:25:39.765858 29927 net.cpp:156] Setting up label_label_0_split
I0216 17:25:39.765869 29927 net.cpp:164] Top shape: 1 1 286 286 (81796)
I0216 17:25:39.765877 29927 net.cpp:164] Top shape: 1 1 286 286 (81796)
I0216 17:25:39.765883 29927 layer_factory.hpp:76] Creating layer conv1
I0216 17:25:39.765895 29927 net.cpp:111] Creating Layer conv1
I0216 17:25:39.765902 29927 net.cpp:478] conv1 <- data_data_0_split_0
I0216 17:25:39.765913 29927 net.cpp:434] conv1 -> conv1
I0216 17:25:39.766940 29927 net.cpp:156] Setting up conv1
I0216 17:25:39.766953 29927 net.cpp:164] Top shape: 1 100 191 191 (3648100)
I0216 17:25:39.766969 29927 layer_factory.hpp:76] Creating layer relu1
I0216 17:25:39.766981 29927 net.cpp:111] Creating Layer relu1
I0216 17:25:39.766988 29927 net.cpp:478] relu1 <- conv1
I0216 17:25:39.766998 29927 net.cpp:420] relu1 -> conv1 (in-place)
I0216 17:25:39.767233 29927 net.cpp:156] Setting up relu1
I0216 17:25:39.767244 29927 net.cpp:164] Top shape: 1 100 191 191 (3648100)
I0216 17:25:39.767252 29927 layer_factory.hpp:76] Creating layer pool1
I0216 17:25:39.767264 29927 net.cpp:111] Creating Layer pool1
I0216 17:25:39.767271 29927 net.cpp:478] pool1 <- conv1
I0216 17:25:39.767279 29927 net.cpp:434] pool1 -> pool1
I0216 17:25:39.767418 29927 net.cpp:156] Setting up pool1
I0216 17:25:39.767431 29927 net.cpp:164] Top shape: 1 100 96 96 (921600)
I0216 17:25:39.767437 29927 layer_factory.hpp:76] Creating layer conv2
I0216 17:25:39.767449 29927 net.cpp:111] Creating Layer conv2
I0216 17:25:39.767457 29927 net.cpp:478] conv2 <- pool1
I0216 17:25:39.767468 29927 net.cpp:434] conv2 -> conv2
I0216 17:25:39.773707 29927 net.cpp:156] Setting up conv2
I0216 17:25:39.773722 29927 net.cpp:164] Top shape: 1 200 46 46 (423200)
I0216 17:25:39.773738 29927 layer_factory.hpp:76] Creating layer relu2
I0216 17:25:39.773749 29927 net.cpp:111] Creating Layer relu2
I0216 17:25:39.773756 29927 net.cpp:478] relu2 <- conv2
I0216 17:25:39.773766 29927 net.cpp:420] relu2 -> conv2 (in-place)
I0216 17:25:39.773905 29927 net.cpp:156] Setting up relu2
I0216 17:25:39.773916 29927 net.cpp:164] Top shape: 1 200 46 46 (423200)
I0216 17:25:39.773923 29927 layer_factory.hpp:76] Creating layer pool2
I0216 17:25:39.773933 29927 net.cpp:111] Creating Layer pool2
I0216 17:25:39.773939 29927 net.cpp:478] pool2 <- conv2
I0216 17:25:39.773957 29927 net.cpp:434] pool2 -> pool2
I0216 17:25:39.774235 29927 net.cpp:156] Setting up pool2
I0216 17:25:39.774255 29927 net.cpp:164] Top shape: 1 200 23 23 (105800)
I0216 17:25:39.774262 29927 layer_factory.hpp:76] Creating layer conv3
I0216 17:25:39.774274 29927 net.cpp:111] Creating Layer conv3
I0216 17:25:39.774281 29927 net.cpp:478] conv3 <- pool2
I0216 17:25:39.774291 29927 net.cpp:434] conv3 -> conv3
I0216 17:25:39.780855 29927 net.cpp:156] Setting up conv3
I0216 17:25:39.780869 29927 net.cpp:164] Top shape: 1 300 21 21 (132300)
I0216 17:25:39.780882 29927 layer_factory.hpp:76] Creating layer relu3
I0216 17:25:39.780891 29927 net.cpp:111] Creating Layer relu3
I0216 17:25:39.780899 29927 net.cpp:478] relu3 <- conv3
I0216 17:25:39.780917 29927 net.cpp:420] relu3 -> conv3 (in-place)
I0216 17:25:39.781054 29927 net.cpp:156] Setting up relu3
I0216 17:25:39.781064 29927 net.cpp:164] Top shape: 1 300 21 21 (132300)
I0216 17:25:39.781071 29927 layer_factory.hpp:76] Creating layer conv4
I0216 17:25:39.781083 29927 net.cpp:111] Creating Layer conv4
I0216 17:25:39.781090 29927 net.cpp:478] conv4 <- conv3
I0216 17:25:39.781101 29927 net.cpp:434] conv4 -> conv4
I0216 17:25:39.790397 29927 net.cpp:156] Setting up conv4
I0216 17:25:39.790412 29927 net.cpp:164] Top shape: 1 300 19 19 (108300)
I0216 17:25:39.790423 29927 layer_factory.hpp:76] Creating layer relu4
I0216 17:25:39.790432 29927 net.cpp:111] Creating Layer relu4
I0216 17:25:39.790439 29927 net.cpp:478] relu4 <- conv4
I0216 17:25:39.790458 29927 net.cpp:420] relu4 -> conv4 (in-place)
I0216 17:25:39.790678 29927 net.cpp:156] Setting up relu4
I0216 17:25:39.790698 29927 net.cpp:164] Top shape: 1 300 19 19 (108300)
I0216 17:25:39.790704 29927 layer_factory.hpp:76] Creating layer drop
I0216 17:25:39.790714 29927 net.cpp:111] Creating Layer drop
I0216 17:25:39.790720 29927 net.cpp:478] drop <- conv4
I0216 17:25:39.790730 29927 net.cpp:420] drop -> conv4 (in-place)
I0216 17:25:39.790742 29927 net.cpp:156] Setting up drop
I0216 17:25:39.790750 29927 net.cpp:164] Top shape: 1 300 19 19 (108300)
I0216 17:25:39.790756 29927 layer_factory.hpp:76] Creating layer score_classes
I0216 17:25:39.790766 29927 net.cpp:111] Creating Layer score_classes
I0216 17:25:39.790771 29927 net.cpp:478] score_classes <- conv4
I0216 17:25:39.790782 29927 net.cpp:434] score_classes -> score_classes
I0216 17:25:39.791380 29927 net.cpp:156] Setting up score_classes
I0216 17:25:39.791393 29927 net.cpp:164] Top shape: 1 2 19 19 (722)
I0216 17:25:39.791407 29927 layer_factory.hpp:76] Creating layer upscore
I0216 17:25:39.791422 29927 net.cpp:111] Creating Layer upscore
I0216 17:25:39.791437 29927 net.cpp:478] upscore <- score_classes
I0216 17:25:39.791447 29927 net.cpp:434] upscore -> upscore
I0216 17:25:39.791926 29927 net.cpp:156] Setting up upscore
I0216 17:25:39.791939 29927 net.cpp:164] Top shape: 1 2 303 303 (183618)
I0216 17:25:39.791950 29927 layer_factory.hpp:76] Creating layer score
I0216 17:25:39.791960 29927 net.cpp:111] Creating Layer score
I0216 17:25:39.791966 29927 net.cpp:478] score <- upscore
I0216 17:25:39.791973 29927 net.cpp:478] score <- data_data_0_split_1
I0216 17:25:39.791985 29927 net.cpp:434] score -> score
I0216 17:25:39.792017 29927 net.cpp:156] Setting up score
I0216 17:25:39.792026 29927 net.cpp:164] Top shape: 1 2 286 286 (163592)
I0216 17:25:39.792033 29927 layer_factory.hpp:76] Creating layer score_score_0_split
I0216 17:25:39.792044 29927 net.cpp:111] Creating Layer score_score_0_split
I0216 17:25:39.792052 29927 net.cpp:478] score_score_0_split <- score
I0216 17:25:39.792059 29927 net.cpp:434] score_score_0_split -> score_score_0_split_0
I0216 17:25:39.792069 29927 net.cpp:434] score_score_0_split -> score_score_0_split_1
I0216 17:25:39.792083 29927 net.cpp:156] Setting up score_score_0_split
I0216 17:25:39.792090 29927 net.cpp:164] Top shape: 1 2 286 286 (163592)
I0216 17:25:39.792099 29927 net.cpp:164] Top shape: 1 2 286 286 (163592)
I0216 17:25:39.792105 29927 layer_factory.hpp:76] Creating layer loss
I0216 17:25:39.792114 29927 net.cpp:111] Creating Layer loss
I0216 17:25:39.792120 29927 net.cpp:478] loss <- score_score_0_split_0
I0216 17:25:39.792127 29927 net.cpp:478] loss <- label_label_0_split_0
I0216 17:25:39.792137 29927 net.cpp:434] loss -> loss
I0216 17:25:39.792150 29927 layer_factory.hpp:76] Creating layer loss
I0216 17:25:39.792461 29927 net.cpp:156] Setting up loss
I0216 17:25:39.792472 29927 net.cpp:164] Top shape: (1)
I0216 17:25:39.792479 29927 net.cpp:169]     with loss weight 1
I0216 17:25:39.792500 29927 layer_factory.hpp:76] Creating layer accuracy
I0216 17:25:39.792510 29927 net.cpp:111] Creating Layer accuracy
I0216 17:25:39.792516 29927 net.cpp:478] accuracy <- score_score_0_split_1
I0216 17:25:39.792523 29927 net.cpp:478] accuracy <- label_label_0_split_1
I0216 17:25:39.792531 29927 net.cpp:434] accuracy -> accuracy
I0216 17:25:39.792542 29927 net.cpp:156] Setting up accuracy
I0216 17:25:39.792551 29927 net.cpp:164] Top shape: (1)
I0216 17:25:39.792557 29927 net.cpp:241] accuracy does not need backward computation.
I0216 17:25:39.792563 29927 net.cpp:237] loss needs backward computation.
I0216 17:25:39.792572 29927 net.cpp:237] score_score_0_split needs backward computation.
I0216 17:25:39.792578 29927 net.cpp:237] score needs backward computation.
I0216 17:25:39.792585 29927 net.cpp:237] upscore needs backward computation.
I0216 17:25:39.792592 29927 net.cpp:237] score_classes needs backward computation.
I0216 17:25:39.792598 29927 net.cpp:237] drop needs backward computation.
I0216 17:25:39.792603 29927 net.cpp:237] relu4 needs backward computation.
I0216 17:25:39.792608 29927 net.cpp:237] conv4 needs backward computation.
I0216 17:25:39.792613 29927 net.cpp:237] relu3 needs backward computation.
I0216 17:25:39.792619 29927 net.cpp:237] conv3 needs backward computation.
I0216 17:25:39.792625 29927 net.cpp:237] pool2 needs backward computation.
I0216 17:25:39.792631 29927 net.cpp:237] relu2 needs backward computation.
I0216 17:25:39.792636 29927 net.cpp:237] conv2 needs backward computation.
I0216 17:25:39.792642 29927 net.cpp:237] pool1 needs backward computation.
I0216 17:25:39.792649 29927 net.cpp:237] relu1 needs backward computation.
I0216 17:25:39.792654 29927 net.cpp:237] conv1 needs backward computation.
I0216 17:25:39.792660 29927 net.cpp:241] label_label_0_split does not need backward computation.
I0216 17:25:39.792667 29927 net.cpp:241] label does not need backward computation.
I0216 17:25:39.792673 29927 net.cpp:241] data_data_0_split does not need backward computation.
I0216 17:25:39.792680 29927 net.cpp:241] data does not need backward computation.
I0216 17:25:39.792685 29927 net.cpp:284] This network produces output accuracy
I0216 17:25:39.792692 29927 net.cpp:284] This network produces output loss
I0216 17:25:39.792711 29927 net.cpp:298] Network initialization done.
I0216 17:25:39.792716 29927 net.cpp:299] Memory required for data: 43701576
I0216 17:25:39.792774 29927 solver.cpp:65] Solver scaffolding done.
I0216 17:25:39.792807 29927 caffe.cpp:201] Resuming from snapshots/fcn_iter_200000.solverstate
I0216 17:25:39.812690 29927 solver.cpp:779] SGDSolver: restoring history
I0216 17:25:39.816781 29927 caffe.cpp:211] Starting Optimization
I0216 17:25:39.816812 29927 solver.cpp:293] Solving FCN
I0216 17:25:39.816818 29927 solver.cpp:294] Learning Rate Policy: multistep
I0216 17:25:39.830487 29927 solver.cpp:242] Iteration 200000, loss = 0.00751544
I0216 17:25:39.830518 29927 solver.cpp:258]     Train net output #0: loss = 0.00751544 (* 1 = 0.00751544 loss)
I0216 17:25:39.830536 29927 solver.cpp:571] Iteration 200000, lr = 0.001
I0216 17:26:12.541620 29927 solver.cpp:449] Snapshotting to binary proto file ./snapshots/fcn_iter_202000.caffemodel
I0216 17:26:12.569658 29927 solver.cpp:734] Snapshotting solver state to binary proto file./snapshots/fcn_iter_202000.solverstate
I0216 17:26:12.585815 29927 solver.cpp:242] Iteration 202000, loss = 0.0130282
I0216 17:26:12.585852 29927 solver.cpp:258]     Train net output #0: loss = 0.00321655 (* 1 = 0.00321655 loss)
I0216 17:26:12.585860 29927 solver.cpp:571] Iteration 202000, lr = 0.001
I0216 17:26:45.138370 29927 solver.cpp:449] Snapshotting to binary proto file ./snapshots/fcn_iter_204000.caffemodel
I0216 17:26:45.166149 29927 solver.cpp:734] Snapshotting solver state to binary proto file./snapshots/fcn_iter_204000.solverstate
I0216 17:26:45.182477 29927 solver.cpp:242] Iteration 204000, loss = 0.01004
I0216 17:26:45.182514 29927 solver.cpp:258]     Train net output #0: loss = 0.00632551 (* 1 = 0.00632551 loss)
I0216 17:26:45.182523 29927 solver.cpp:571] Iteration 204000, lr = 0.001
I0216 17:27:17.636239 29927 solver.cpp:449] Snapshotting to binary proto file ./snapshots/fcn_iter_206000.caffemodel
I0216 17:27:17.662708 29927 solver.cpp:734] Snapshotting solver state to binary proto file./snapshots/fcn_iter_206000.solverstate
I0216 17:27:17.678076 29927 solver.cpp:242] Iteration 206000, loss = 0.0119894
I0216 17:27:17.678112 29927 solver.cpp:258]     Train net output #0: loss = 0.00959371 (* 1 = 0.00959371 loss)
I0216 17:27:17.678120 29927 solver.cpp:571] Iteration 206000, lr = 0.001
I0216 17:27:50.799080 29927 solver.cpp:449] Snapshotting to binary proto file ./snapshots/fcn_iter_208000.caffemodel
I0216 17:27:50.826457 29927 solver.cpp:734] Snapshotting solver state to binary proto file./snapshots/fcn_iter_208000.solverstate
I0216 17:27:50.843057 29927 solver.cpp:242] Iteration 208000, loss = 0.0109835
I0216 17:27:50.843094 29927 solver.cpp:258]     Train net output #0: loss = 0.0109918 (* 1 = 0.0109918 loss)
I0216 17:27:50.843101 29927 solver.cpp:571] Iteration 208000, lr = 0.001
I0216 17:28:23.685220 29927 solver.cpp:449] Snapshotting to binary proto file ./snapshots/fcn_iter_210000.caffemodel
I0216 17:28:23.712836 29927 solver.cpp:734] Snapshotting solver state to binary proto file./snapshots/fcn_iter_210000.solverstate
I0216 17:28:23.729857 29927 solver.cpp:242] Iteration 210000, loss = 0.0122993
I0216 17:28:23.729903 29927 solver.cpp:258]     Train net output #0: loss = 0.00688017 (* 1 = 0.00688017 loss)
I0216 17:28:23.729912 29927 solver.cpp:571] Iteration 210000, lr = 0.001
I0216 17:28:56.645867 29927 solver.cpp:449] Snapshotting to binary proto file ./snapshots/fcn_iter_212000.caffemodel
I0216 17:28:56.675603 29927 solver.cpp:734] Snapshotting solver state to binary proto file./snapshots/fcn_iter_212000.solverstate
I0216 17:28:56.690620 29927 solver.cpp:242] Iteration 212000, loss = 0.0138596
I0216 17:28:56.690665 29927 solver.cpp:258]     Train net output #0: loss = 0.0218714 (* 1 = 0.0218714 loss)
I0216 17:28:56.690673 29927 solver.cpp:571] Iteration 212000, lr = 0.001
I0216 17:29:29.826483 29927 solver.cpp:449] Snapshotting to binary proto file ./snapshots/fcn_iter_214000.caffemodel
I0216 17:29:29.855931 29927 solver.cpp:734] Snapshotting solver state to binary proto file./snapshots/fcn_iter_214000.solverstate
I0216 17:29:29.871121 29927 solver.cpp:242] Iteration 214000, loss = 0.0113044
I0216 17:29:29.871165 29927 solver.cpp:258]     Train net output #0: loss = 0.00200459 (* 1 = 0.00200459 loss)
I0216 17:29:29.871175 29927 solver.cpp:571] Iteration 214000, lr = 0.001
I0216 17:30:02.837270 29927 solver.cpp:449] Snapshotting to binary proto file ./snapshots/fcn_iter_216000.caffemodel
I0216 17:30:02.863507 29927 solver.cpp:734] Snapshotting solver state to binary proto file./snapshots/fcn_iter_216000.solverstate
I0216 17:30:02.879178 29927 solver.cpp:242] Iteration 216000, loss = 0.0118999
I0216 17:30:02.879215 29927 solver.cpp:258]     Train net output #0: loss = 0.0163926 (* 1 = 0.0163926 loss)
I0216 17:30:02.879223 29927 solver.cpp:571] Iteration 216000, lr = 0.001
I0216 17:30:35.743993 29927 solver.cpp:449] Snapshotting to binary proto file ./snapshots/fcn_iter_218000.caffemodel
I0216 17:30:35.774410 29927 solver.cpp:734] Snapshotting solver state to binary proto file./snapshots/fcn_iter_218000.solverstate
I0216 17:30:35.791095 29927 solver.cpp:242] Iteration 218000, loss = 0.0133291
I0216 17:30:35.791131 29927 solver.cpp:258]     Train net output #0: loss = 0.0179216 (* 1 = 0.0179216 loss)
I0216 17:30:35.791138 29927 solver.cpp:571] Iteration 218000, lr = 0.001
I0216 17:31:08.723628 29927 solver.cpp:449] Snapshotting to binary proto file ./snapshots/fcn_iter_220000.caffemodel
I0216 17:31:08.753506 29927 solver.cpp:734] Snapshotting solver state to binary proto file./snapshots/fcn_iter_220000.solverstate
I0216 17:31:08.773119 29927 solver.cpp:242] Iteration 220000, loss = 0.0119767
I0216 17:31:08.773155 29927 solver.cpp:258]     Train net output #0: loss = 0.0069449 (* 1 = 0.0069449 loss)
I0216 17:31:08.773164 29927 solver.cpp:571] Iteration 220000, lr = 0.001
I0216 17:31:41.699463 29927 solver.cpp:449] Snapshotting to binary proto file ./snapshots/fcn_iter_222000.caffemodel
I0216 17:31:41.729689 29927 solver.cpp:734] Snapshotting solver state to binary proto file./snapshots/fcn_iter_222000.solverstate
I0216 17:31:41.745797 29927 solver.cpp:242] Iteration 222000, loss = 0.011409
I0216 17:31:41.745833 29927 solver.cpp:258]     Train net output #0: loss = 0.00461706 (* 1 = 0.00461706 loss)
I0216 17:31:41.745841 29927 solver.cpp:571] Iteration 222000, lr = 0.001
I0216 17:32:14.628384 29927 solver.cpp:449] Snapshotting to binary proto file ./snapshots/fcn_iter_224000.caffemodel
I0216 17:32:14.660432 29927 solver.cpp:734] Snapshotting solver state to binary proto file./snapshots/fcn_iter_224000.solverstate
I0216 17:32:14.679684 29927 solver.cpp:242] Iteration 224000, loss = 0.0113757
I0216 17:32:14.679720 29927 solver.cpp:258]     Train net output #0: loss = 0.0152414 (* 1 = 0.0152414 loss)
I0216 17:32:14.679728 29927 solver.cpp:571] Iteration 224000, lr = 0.001
I0216 17:32:47.651268 29927 solver.cpp:449] Snapshotting to binary proto file ./snapshots/fcn_iter_226000.caffemodel
I0216 17:32:47.683202 29927 solver.cpp:734] Snapshotting solver state to binary proto file./snapshots/fcn_iter_226000.solverstate
I0216 17:32:47.697758 29927 solver.cpp:242] Iteration 226000, loss = 0.00959374
I0216 17:32:47.697794 29927 solver.cpp:258]     Train net output #0: loss = 0.046259 (* 1 = 0.046259 loss)
I0216 17:32:47.697803 29927 solver.cpp:571] Iteration 226000, lr = 0.001
I0216 17:33:20.784147 29927 solver.cpp:449] Snapshotting to binary proto file ./snapshots/fcn_iter_228000.caffemodel
I0216 17:33:20.812939 29927 solver.cpp:734] Snapshotting solver state to binary proto file./snapshots/fcn_iter_228000.solverstate
I0216 17:33:20.830549 29927 solver.cpp:242] Iteration 228000, loss = 0.0108712
I0216 17:33:20.830595 29927 solver.cpp:258]     Train net output #0: loss = 0.00757477 (* 1 = 0.00757477 loss)
I0216 17:33:20.830602 29927 solver.cpp:571] Iteration 228000, lr = 0.001
I0216 17:33:53.600481 29927 solver.cpp:449] Snapshotting to binary proto file ./snapshots/fcn_iter_230000.caffemodel
I0216 17:33:53.630475 29927 solver.cpp:734] Snapshotting solver state to binary proto file./snapshots/fcn_iter_230000.solverstate
I0216 17:33:53.647145 29927 solver.cpp:242] Iteration 230000, loss = 0.0139445
I0216 17:33:53.647181 29927 solver.cpp:258]     Train net output #0: loss = 0.00361488 (* 1 = 0.00361488 loss)
I0216 17:33:53.647189 29927 solver.cpp:571] Iteration 230000, lr = 0.001
I0216 17:34:26.615129 29927 solver.cpp:449] Snapshotting to binary proto file ./snapshots/fcn_iter_232000.caffemodel
I0216 17:34:26.643208 29927 solver.cpp:734] Snapshotting solver state to binary proto file./snapshots/fcn_iter_232000.solverstate
I0216 17:34:26.658077 29927 solver.cpp:242] Iteration 232000, loss = 0.0108133
I0216 17:34:26.658113 29927 solver.cpp:258]     Train net output #0: loss = 0.00227878 (* 1 = 0.00227878 loss)
I0216 17:34:26.658120 29927 solver.cpp:571] Iteration 232000, lr = 0.001
I0216 17:34:59.535037 29927 solver.cpp:449] Snapshotting to binary proto file ./snapshots/fcn_iter_234000.caffemodel
I0216 17:34:59.566460 29927 solver.cpp:734] Snapshotting solver state to binary proto file./snapshots/fcn_iter_234000.solverstate
I0216 17:34:59.584568 29927 solver.cpp:242] Iteration 234000, loss = 0.0100775
I0216 17:34:59.584604 29927 solver.cpp:258]     Train net output #0: loss = 0.00475562 (* 1 = 0.00475562 loss)
I0216 17:34:59.584612 29927 solver.cpp:571] Iteration 234000, lr = 0.001
I0216 17:35:32.590184 29927 solver.cpp:449] Snapshotting to binary proto file ./snapshots/fcn_iter_236000.caffemodel
I0216 17:35:32.618187 29927 solver.cpp:734] Snapshotting solver state to binary proto file./snapshots/fcn_iter_236000.solverstate
I0216 17:35:32.632441 29927 solver.cpp:242] Iteration 236000, loss = 0.00932712
I0216 17:35:32.632478 29927 solver.cpp:258]     Train net output #0: loss = 0.00420506 (* 1 = 0.00420506 loss)
I0216 17:35:32.632485 29927 solver.cpp:571] Iteration 236000, lr = 0.001
I0216 17:36:05.570673 29927 solver.cpp:449] Snapshotting to binary proto file ./snapshots/fcn_iter_238000.caffemodel
I0216 17:36:05.598850 29927 solver.cpp:734] Snapshotting solver state to binary proto file./snapshots/fcn_iter_238000.solverstate
I0216 17:36:05.613931 29927 solver.cpp:242] Iteration 238000, loss = 0.0109002
I0216 17:36:05.613968 29927 solver.cpp:258]     Train net output #0: loss = 0.00535657 (* 1 = 0.00535657 loss)
I0216 17:36:05.613976 29927 solver.cpp:571] Iteration 238000, lr = 0.001
I0216 17:36:38.467466 29927 solver.cpp:449] Snapshotting to binary proto file ./snapshots/fcn_iter_240000.caffemodel
I0216 17:36:38.495435 29927 solver.cpp:734] Snapshotting solver state to binary proto file./snapshots/fcn_iter_240000.solverstate
I0216 17:36:38.510419 29927 solver.cpp:242] Iteration 240000, loss = 0.0109779
I0216 17:36:38.510457 29927 solver.cpp:258]     Train net output #0: loss = 0.0172572 (* 1 = 0.0172572 loss)
I0216 17:36:38.510464 29927 solver.cpp:571] Iteration 240000, lr = 0.001
I0216 17:37:11.580951 29927 solver.cpp:449] Snapshotting to binary proto file ./snapshots/fcn_iter_242000.caffemodel
I0216 17:37:11.609190 29927 solver.cpp:734] Snapshotting solver state to binary proto file./snapshots/fcn_iter_242000.solverstate
I0216 17:37:11.625741 29927 solver.cpp:242] Iteration 242000, loss = 0.0124669
I0216 17:37:11.625777 29927 solver.cpp:258]     Train net output #0: loss = 0.00885128 (* 1 = 0.00885128 loss)
I0216 17:37:11.625785 29927 solver.cpp:571] Iteration 242000, lr = 0.001
I0216 17:37:44.576671 29927 solver.cpp:449] Snapshotting to binary proto file ./snapshots/fcn_iter_244000.caffemodel
I0216 17:37:44.606008 29927 solver.cpp:734] Snapshotting solver state to binary proto file./snapshots/fcn_iter_244000.solverstate
I0216 17:37:44.621040 29927 solver.cpp:242] Iteration 244000, loss = 0.0121745
I0216 17:37:44.621076 29927 solver.cpp:258]     Train net output #0: loss = 0.00940041 (* 1 = 0.00940041 loss)
I0216 17:37:44.621084 29927 solver.cpp:571] Iteration 244000, lr = 0.001
I0216 17:38:17.351982 29927 solver.cpp:449] Snapshotting to binary proto file ./snapshots/fcn_iter_246000.caffemodel
I0216 17:38:17.380290 29927 solver.cpp:734] Snapshotting solver state to binary proto file./snapshots/fcn_iter_246000.solverstate
I0216 17:38:17.397634 29927 solver.cpp:242] Iteration 246000, loss = 0.0115706
I0216 17:38:17.397680 29927 solver.cpp:258]     Train net output #0: loss = 0.00316307 (* 1 = 0.00316307 loss)
I0216 17:38:17.397687 29927 solver.cpp:571] Iteration 246000, lr = 0.001
I0216 17:38:50.220661 29927 solver.cpp:449] Snapshotting to binary proto file ./snapshots/fcn_iter_248000.caffemodel
I0216 17:38:50.251991 29927 solver.cpp:734] Snapshotting solver state to binary proto file./snapshots/fcn_iter_248000.solverstate
I0216 17:38:50.267061 29927 solver.cpp:242] Iteration 248000, loss = 0.0103218
I0216 17:38:50.267109 29927 solver.cpp:258]     Train net output #0: loss = 0.00623573 (* 1 = 0.00623573 loss)
I0216 17:38:50.267118 29927 solver.cpp:571] Iteration 248000, lr = 0.001
I0216 17:39:22.965303 29927 solver.cpp:449] Snapshotting to binary proto file ./snapshots/fcn_iter_250000.caffemodel
I0216 17:39:22.993568 29927 solver.cpp:734] Snapshotting solver state to binary proto file./snapshots/fcn_iter_250000.solverstate
I0216 17:39:23.011389 29927 solver.cpp:242] Iteration 250000, loss = 0.0119022
I0216 17:39:23.011425 29927 solver.cpp:258]     Train net output #0: loss = 0.0164524 (* 1 = 0.0164524 loss)
I0216 17:39:23.011433 29927 solver.cpp:571] Iteration 250000, lr = 0.001
I0216 17:39:55.952853 29927 solver.cpp:449] Snapshotting to binary proto file ./snapshots/fcn_iter_252000.caffemodel
I0216 17:39:55.984097 29927 solver.cpp:734] Snapshotting solver state to binary proto file./snapshots/fcn_iter_252000.solverstate
I0216 17:39:55.998229 29927 solver.cpp:242] Iteration 252000, loss = 0.0112653
I0216 17:39:55.998265 29927 solver.cpp:258]     Train net output #0: loss = 0.00355233 (* 1 = 0.00355233 loss)
I0216 17:39:55.998273 29927 solver.cpp:571] Iteration 252000, lr = 0.001
I0216 17:40:29.043197 29927 solver.cpp:449] Snapshotting to binary proto file ./snapshots/fcn_iter_254000.caffemodel
I0216 17:40:29.071221 29927 solver.cpp:734] Snapshotting solver state to binary proto file./snapshots/fcn_iter_254000.solverstate
I0216 17:40:29.087054 29927 solver.cpp:242] Iteration 254000, loss = 0.0119928
I0216 17:40:29.087090 29927 solver.cpp:258]     Train net output #0: loss = 0.00860662 (* 1 = 0.00860662 loss)
I0216 17:40:29.087098 29927 solver.cpp:571] Iteration 254000, lr = 0.001
I0216 17:41:02.076350 29927 solver.cpp:449] Snapshotting to binary proto file ./snapshots/fcn_iter_256000.caffemodel
I0216 17:41:02.104694 29927 solver.cpp:734] Snapshotting solver state to binary proto file./snapshots/fcn_iter_256000.solverstate
I0216 17:41:02.122297 29927 solver.cpp:242] Iteration 256000, loss = 0.00967225
I0216 17:41:02.122336 29927 solver.cpp:258]     Train net output #0: loss = 0.00539636 (* 1 = 0.00539636 loss)
I0216 17:41:02.122356 29927 solver.cpp:571] Iteration 256000, lr = 0.001
I0216 17:41:34.985221 29927 solver.cpp:449] Snapshotting to binary proto file ./snapshots/fcn_iter_258000.caffemodel
I0216 17:41:35.013140 29927 solver.cpp:734] Snapshotting solver state to binary proto file./snapshots/fcn_iter_258000.solverstate
I0216 17:41:35.028267 29927 solver.cpp:242] Iteration 258000, loss = 0.00909821
I0216 17:41:35.028308 29927 solver.cpp:258]     Train net output #0: loss = 0.00485025 (* 1 = 0.00485025 loss)
I0216 17:41:35.028321 29927 solver.cpp:571] Iteration 258000, lr = 0.001
I0216 17:42:08.002660 29927 solver.cpp:449] Snapshotting to binary proto file ./snapshots/fcn_iter_260000.caffemodel
I0216 17:42:08.030907 29927 solver.cpp:734] Snapshotting solver state to binary proto file./snapshots/fcn_iter_260000.solverstate
I0216 17:42:08.047514 29927 solver.cpp:242] Iteration 260000, loss = 0.00939477
I0216 17:42:08.047552 29927 solver.cpp:258]     Train net output #0: loss = 0.0410139 (* 1 = 0.0410139 loss)
I0216 17:42:08.047561 29927 solver.cpp:571] Iteration 260000, lr = 0.001
I0216 17:42:41.050355 29927 solver.cpp:449] Snapshotting to binary proto file ./snapshots/fcn_iter_262000.caffemodel
I0216 17:42:41.080291 29927 solver.cpp:734] Snapshotting solver state to binary proto file./snapshots/fcn_iter_262000.solverstate
I0216 17:42:41.095479 29927 solver.cpp:242] Iteration 262000, loss = 0.0115095
I0216 17:42:41.095525 29927 solver.cpp:258]     Train net output #0: loss = 0.041687 (* 1 = 0.041687 loss)
I0216 17:42:41.095533 29927 solver.cpp:571] Iteration 262000, lr = 0.001
I0216 17:43:13.953632 29927 solver.cpp:449] Snapshotting to binary proto file ./snapshots/fcn_iter_264000.caffemodel
I0216 17:43:13.983579 29927 solver.cpp:734] Snapshotting solver state to binary proto file./snapshots/fcn_iter_264000.solverstate
I0216 17:43:14.000140 29927 solver.cpp:242] Iteration 264000, loss = 0.010578
I0216 17:43:14.000177 29927 solver.cpp:258]     Train net output #0: loss = 0.00410049 (* 1 = 0.00410049 loss)
I0216 17:43:14.000186 29927 solver.cpp:571] Iteration 264000, lr = 0.001
I0216 17:43:46.733381 29927 solver.cpp:449] Snapshotting to binary proto file ./snapshots/fcn_iter_266000.caffemodel
I0216 17:43:46.762022 29927 solver.cpp:734] Snapshotting solver state to binary proto file./snapshots/fcn_iter_266000.solverstate
I0216 17:43:46.778676 29927 solver.cpp:242] Iteration 266000, loss = 0.00939053
I0216 17:43:46.778723 29927 solver.cpp:258]     Train net output #0: loss = 0.0059857 (* 1 = 0.0059857 loss)
I0216 17:43:46.778730 29927 solver.cpp:571] Iteration 266000, lr = 0.001
I0216 17:44:19.857125 29927 solver.cpp:449] Snapshotting to binary proto file ./snapshots/fcn_iter_268000.caffemodel
I0216 17:44:19.884863 29927 solver.cpp:734] Snapshotting solver state to binary proto file./snapshots/fcn_iter_268000.solverstate
I0216 17:44:19.901484 29927 solver.cpp:242] Iteration 268000, loss = 0.0108155
I0216 17:44:19.901518 29927 solver.cpp:258]     Train net output #0: loss = 0.0038397 (* 1 = 0.0038397 loss)
I0216 17:44:19.901527 29927 solver.cpp:571] Iteration 268000, lr = 0.001
I0216 17:44:52.861663 29927 solver.cpp:449] Snapshotting to binary proto file ./snapshots/fcn_iter_270000.caffemodel
I0216 17:44:52.890283 29927 solver.cpp:734] Snapshotting solver state to binary proto file./snapshots/fcn_iter_270000.solverstate
I0216 17:44:52.907780 29927 solver.cpp:242] Iteration 270000, loss = 0.0130971
I0216 17:44:52.907816 29927 solver.cpp:258]     Train net output #0: loss = 0.00914984 (* 1 = 0.00914984 loss)
I0216 17:44:52.907825 29927 solver.cpp:571] Iteration 270000, lr = 0.001
I0216 17:45:25.534649 29927 solver.cpp:449] Snapshotting to binary proto file ./snapshots/fcn_iter_272000.caffemodel
I0216 17:45:25.563347 29927 solver.cpp:734] Snapshotting solver state to binary proto file./snapshots/fcn_iter_272000.solverstate
I0216 17:45:25.579394 29927 solver.cpp:242] Iteration 272000, loss = 0.00977905
I0216 17:45:25.579440 29927 solver.cpp:258]     Train net output #0: loss = 0.00377065 (* 1 = 0.00377065 loss)
I0216 17:45:25.579448 29927 solver.cpp:571] Iteration 272000, lr = 0.001
I0216 17:45:58.388679 29927 solver.cpp:449] Snapshotting to binary proto file ./snapshots/fcn_iter_274000.caffemodel
I0216 17:45:58.421248 29927 solver.cpp:734] Snapshotting solver state to binary proto file./snapshots/fcn_iter_274000.solverstate
I0216 17:45:58.435940 29927 solver.cpp:242] Iteration 274000, loss = 0.0104714
I0216 17:45:58.435977 29927 solver.cpp:258]     Train net output #0: loss = 0.00230947 (* 1 = 0.00230947 loss)
I0216 17:45:58.435986 29927 solver.cpp:571] Iteration 274000, lr = 0.001
I0216 17:46:31.450443 29927 solver.cpp:449] Snapshotting to binary proto file ./snapshots/fcn_iter_276000.caffemodel
I0216 17:46:31.478814 29927 solver.cpp:734] Snapshotting solver state to binary proto file./snapshots/fcn_iter_276000.solverstate
I0216 17:46:31.493651 29927 solver.cpp:242] Iteration 276000, loss = 0.0110637
I0216 17:46:31.493688 29927 solver.cpp:258]     Train net output #0: loss = 0.0146768 (* 1 = 0.0146768 loss)
I0216 17:46:31.493697 29927 solver.cpp:571] Iteration 276000, lr = 0.001
I0216 17:47:04.363575 29927 solver.cpp:449] Snapshotting to binary proto file ./snapshots/fcn_iter_278000.caffemodel
I0216 17:47:04.391327 29927 solver.cpp:734] Snapshotting solver state to binary proto file./snapshots/fcn_iter_278000.solverstate
I0216 17:47:04.406529 29927 solver.cpp:242] Iteration 278000, loss = 0.00872085
I0216 17:47:04.406566 29927 solver.cpp:258]     Train net output #0: loss = 0.0050456 (* 1 = 0.0050456 loss)
I0216 17:47:04.406574 29927 solver.cpp:571] Iteration 278000, lr = 0.001
I0216 17:47:37.273497 29927 solver.cpp:449] Snapshotting to binary proto file ./snapshots/fcn_iter_280000.caffemodel
I0216 17:47:37.302076 29927 solver.cpp:734] Snapshotting solver state to binary proto file./snapshots/fcn_iter_280000.solverstate
I0216 17:47:37.318725 29927 solver.cpp:242] Iteration 280000, loss = 0.012392
I0216 17:47:37.318773 29927 solver.cpp:258]     Train net output #0: loss = 0.00239943 (* 1 = 0.00239943 loss)
I0216 17:47:37.318780 29927 solver.cpp:571] Iteration 280000, lr = 0.001
I0216 17:48:10.386142 29927 solver.cpp:449] Snapshotting to binary proto file ./snapshots/fcn_iter_282000.caffemodel
I0216 17:48:10.415756 29927 solver.cpp:734] Snapshotting solver state to binary proto file./snapshots/fcn_iter_282000.solverstate
I0216 17:48:10.430106 29927 solver.cpp:242] Iteration 282000, loss = 0.012324
I0216 17:48:10.430142 29927 solver.cpp:258]     Train net output #0: loss = 0.0129659 (* 1 = 0.0129659 loss)
I0216 17:48:10.430150 29927 solver.cpp:571] Iteration 282000, lr = 0.001
I0216 17:48:43.285310 29927 solver.cpp:449] Snapshotting to binary proto file ./snapshots/fcn_iter_284000.caffemodel
I0216 17:48:43.311902 29927 solver.cpp:734] Snapshotting solver state to binary proto file./snapshots/fcn_iter_284000.solverstate
I0216 17:48:43.331485 29927 solver.cpp:242] Iteration 284000, loss = 0.0119984
I0216 17:48:43.331524 29927 solver.cpp:258]     Train net output #0: loss = 0.0329465 (* 1 = 0.0329465 loss)
I0216 17:48:43.331532 29927 solver.cpp:571] Iteration 284000, lr = 0.001
I0216 17:49:16.351830 29927 solver.cpp:449] Snapshotting to binary proto file ./snapshots/fcn_iter_286000.caffemodel
I0216 17:49:16.381669 29927 solver.cpp:734] Snapshotting solver state to binary proto file./snapshots/fcn_iter_286000.solverstate
I0216 17:49:16.397464 29927 solver.cpp:242] Iteration 286000, loss = 0.0108875
I0216 17:49:16.397511 29927 solver.cpp:258]     Train net output #0: loss = 0.00267476 (* 1 = 0.00267476 loss)
I0216 17:49:16.397518 29927 solver.cpp:571] Iteration 286000, lr = 0.001
I0216 17:49:49.263568 29927 solver.cpp:449] Snapshotting to binary proto file ./snapshots/fcn_iter_288000.caffemodel
I0216 17:49:49.293879 29927 solver.cpp:734] Snapshotting solver state to binary proto file./snapshots/fcn_iter_288000.solverstate
I0216 17:49:49.309013 29927 solver.cpp:242] Iteration 288000, loss = 0.0126055
I0216 17:49:49.309061 29927 solver.cpp:258]     Train net output #0: loss = 0.00603741 (* 1 = 0.00603741 loss)
I0216 17:49:49.309068 29927 solver.cpp:571] Iteration 288000, lr = 0.001
I0216 17:50:22.150621 29927 solver.cpp:449] Snapshotting to binary proto file ./snapshots/fcn_iter_290000.caffemodel
I0216 17:50:22.179100 29927 solver.cpp:734] Snapshotting solver state to binary proto file./snapshots/fcn_iter_290000.solverstate
I0216 17:50:22.194031 29927 solver.cpp:242] Iteration 290000, loss = 0.0141924
I0216 17:50:22.194078 29927 solver.cpp:258]     Train net output #0: loss = 0.0103447 (* 1 = 0.0103447 loss)
I0216 17:50:22.194087 29927 solver.cpp:571] Iteration 290000, lr = 0.001
I0216 17:50:55.210147 29927 solver.cpp:449] Snapshotting to binary proto file ./snapshots/fcn_iter_292000.caffemodel
I0216 17:50:55.238669 29927 solver.cpp:734] Snapshotting solver state to binary proto file./snapshots/fcn_iter_292000.solverstate
I0216 17:50:55.253801 29927 solver.cpp:242] Iteration 292000, loss = 0.0113434
I0216 17:50:55.253839 29927 solver.cpp:258]     Train net output #0: loss = 0.00745139 (* 1 = 0.00745139 loss)
I0216 17:50:55.253846 29927 solver.cpp:571] Iteration 292000, lr = 0.001
I0216 17:51:28.154639 29927 solver.cpp:449] Snapshotting to binary proto file ./snapshots/fcn_iter_294000.caffemodel
I0216 17:51:28.181821 29927 solver.cpp:734] Snapshotting solver state to binary proto file./snapshots/fcn_iter_294000.solverstate
I0216 17:51:28.196797 29927 solver.cpp:242] Iteration 294000, loss = 0.0108271
I0216 17:51:28.196835 29927 solver.cpp:258]     Train net output #0: loss = 0.00361779 (* 1 = 0.00361779 loss)
I0216 17:51:28.196843 29927 solver.cpp:571] Iteration 294000, lr = 0.001
I0216 17:52:01.066668 29927 solver.cpp:449] Snapshotting to binary proto file ./snapshots/fcn_iter_296000.caffemodel
I0216 17:52:01.095288 29927 solver.cpp:734] Snapshotting solver state to binary proto file./snapshots/fcn_iter_296000.solverstate
I0216 17:52:01.111160 29927 solver.cpp:242] Iteration 296000, loss = 0.0123462
I0216 17:52:01.111196 29927 solver.cpp:258]     Train net output #0: loss = 0.0129021 (* 1 = 0.0129021 loss)
I0216 17:52:01.111203 29927 solver.cpp:571] Iteration 296000, lr = 0.001
I0216 17:52:34.067108 29927 solver.cpp:449] Snapshotting to binary proto file ./snapshots/fcn_iter_298000.caffemodel
I0216 17:52:34.099943 29927 solver.cpp:734] Snapshotting solver state to binary proto file./snapshots/fcn_iter_298000.solverstate
I0216 17:52:34.117496 29927 solver.cpp:242] Iteration 298000, loss = 0.0121319
I0216 17:52:34.117533 29927 solver.cpp:258]     Train net output #0: loss = 0.00317984 (* 1 = 0.00317984 loss)
I0216 17:52:34.117542 29927 solver.cpp:571] Iteration 298000, lr = 0.001
I0216 17:53:07.062659 29927 solver.cpp:449] Snapshotting to binary proto file ./snapshots/fcn_iter_300000.caffemodel
I0216 17:53:07.091238 29927 solver.cpp:734] Snapshotting solver state to binary proto file./snapshots/fcn_iter_300000.solverstate
I0216 17:53:07.106230 29927 solver.cpp:242] Iteration 300000, loss = 0.0130829
I0216 17:53:07.106267 29927 solver.cpp:258]     Train net output #0: loss = 0.00357383 (* 1 = 0.00357383 loss)
I0216 17:53:07.106276 29927 solver.cpp:571] Iteration 300000, lr = 0.001
